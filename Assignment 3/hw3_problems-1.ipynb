{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede484aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 3\n",
    "\n",
    "## Assignment Info\n",
    "Homework #: HW3 \\\n",
    "Description: PCA \\\n",
    "Course: EN.553.636 Introduction to Data Science \\\n",
    "Semester: Spring 2023, Homewood Campus\t\\\n",
    "Instructor: Tamas Budavari \\\n",
    "TA: Matthew Tivnan \\\n",
    "Date: February 25, 2023 \n",
    "\n",
    "## Student Info\n",
    "Name: Amir Hossein Daraie \\\n",
    "JHED-ID: adaraie1 \\\n",
    "Email: adaraie1@jhu.edu \n",
    "\n",
    "We load the `music_scaled.csv` dataset ([source](https://archive.ics.uci.edu/ml/datasets/Geographical+Original+of+Music#)). The dataset contains a sample of traditional songs from different cultures. Features F1 to F68 are quantitative summaries of the songs from audio analysis software. These features have been subject to standard scaling. They are stored as predictors in `X.` The latitudes of the countries from which the songs originate are stored as a target variable `y.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fd54ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F59</th>\n",
       "      <th>F60</th>\n",
       "      <th>F61</th>\n",
       "      <th>F62</th>\n",
       "      <th>F63</th>\n",
       "      <th>F64</th>\n",
       "      <th>F65</th>\n",
       "      <th>F66</th>\n",
       "      <th>F67</th>\n",
       "      <th>F68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.094000</td>\n",
       "      <td>-1.280592</td>\n",
       "      <td>2.806926</td>\n",
       "      <td>-0.097576</td>\n",
       "      <td>-0.791472</td>\n",
       "      <td>2.440896</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>-0.864715</td>\n",
       "      <td>0.738257</td>\n",
       "      <td>-0.185613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465685</td>\n",
       "      <td>1.651588</td>\n",
       "      <td>0.169668</td>\n",
       "      <td>0.348005</td>\n",
       "      <td>-0.385988</td>\n",
       "      <td>-0.137105</td>\n",
       "      <td>-0.421766</td>\n",
       "      <td>-0.296043</td>\n",
       "      <td>-0.731677</td>\n",
       "      <td>-0.442480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.285544</td>\n",
       "      <td>-0.940198</td>\n",
       "      <td>-0.721321</td>\n",
       "      <td>-0.172044</td>\n",
       "      <td>-2.127893</td>\n",
       "      <td>2.549762</td>\n",
       "      <td>1.365750</td>\n",
       "      <td>0.489953</td>\n",
       "      <td>1.692462</td>\n",
       "      <td>0.387044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534732</td>\n",
       "      <td>-0.935377</td>\n",
       "      <td>-1.176909</td>\n",
       "      <td>-1.408592</td>\n",
       "      <td>-0.986426</td>\n",
       "      <td>-1.293346</td>\n",
       "      <td>-1.239692</td>\n",
       "      <td>-0.729675</td>\n",
       "      <td>-1.153275</td>\n",
       "      <td>-1.254825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.503962</td>\n",
       "      <td>0.497136</td>\n",
       "      <td>-0.319168</td>\n",
       "      <td>0.330719</td>\n",
       "      <td>-0.398783</td>\n",
       "      <td>-0.749429</td>\n",
       "      <td>-2.380589</td>\n",
       "      <td>0.951098</td>\n",
       "      <td>-0.452177</td>\n",
       "      <td>-0.761333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274432</td>\n",
       "      <td>0.150854</td>\n",
       "      <td>0.161782</td>\n",
       "      <td>0.101072</td>\n",
       "      <td>-0.071694</td>\n",
       "      <td>-0.835381</td>\n",
       "      <td>-0.397305</td>\n",
       "      <td>-0.456676</td>\n",
       "      <td>-0.492329</td>\n",
       "      <td>-0.761836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.119978</td>\n",
       "      <td>0.696697</td>\n",
       "      <td>0.612882</td>\n",
       "      <td>-0.983295</td>\n",
       "      <td>1.333148</td>\n",
       "      <td>1.557607</td>\n",
       "      <td>-0.999593</td>\n",
       "      <td>-1.067051</td>\n",
       "      <td>0.811559</td>\n",
       "      <td>0.437626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696481</td>\n",
       "      <td>0.091214</td>\n",
       "      <td>-0.051819</td>\n",
       "      <td>0.219476</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>-0.088704</td>\n",
       "      <td>-0.068108</td>\n",
       "      <td>-0.070306</td>\n",
       "      <td>0.277593</td>\n",
       "      <td>-0.071959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.256214</td>\n",
       "      <td>1.066239</td>\n",
       "      <td>0.984965</td>\n",
       "      <td>-0.312513</td>\n",
       "      <td>-2.111077</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.509741</td>\n",
       "      <td>0.837961</td>\n",
       "      <td>0.420966</td>\n",
       "      <td>0.366289</td>\n",
       "      <td>...</td>\n",
       "      <td>1.816629</td>\n",
       "      <td>0.593634</td>\n",
       "      <td>0.746647</td>\n",
       "      <td>0.035940</td>\n",
       "      <td>-0.292118</td>\n",
       "      <td>0.075086</td>\n",
       "      <td>-0.238434</td>\n",
       "      <td>-0.347040</td>\n",
       "      <td>-0.693764</td>\n",
       "      <td>0.053940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0.089066</td>\n",
       "      <td>0.045324</td>\n",
       "      <td>-0.527161</td>\n",
       "      <td>0.274475</td>\n",
       "      <td>0.113220</td>\n",
       "      <td>-1.011250</td>\n",
       "      <td>-1.071873</td>\n",
       "      <td>-1.533993</td>\n",
       "      <td>-3.432258</td>\n",
       "      <td>-5.225601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269233</td>\n",
       "      <td>3.032646</td>\n",
       "      <td>3.000290</td>\n",
       "      <td>2.279520</td>\n",
       "      <td>3.409849</td>\n",
       "      <td>-0.028728</td>\n",
       "      <td>1.661721</td>\n",
       "      <td>3.501781</td>\n",
       "      <td>2.685491</td>\n",
       "      <td>1.111113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0.558342</td>\n",
       "      <td>0.274368</td>\n",
       "      <td>-0.356357</td>\n",
       "      <td>-0.410656</td>\n",
       "      <td>0.710800</td>\n",
       "      <td>-0.240603</td>\n",
       "      <td>-0.370162</td>\n",
       "      <td>0.870655</td>\n",
       "      <td>-1.488764</td>\n",
       "      <td>0.566561</td>\n",
       "      <td>...</td>\n",
       "      <td>1.723216</td>\n",
       "      <td>3.048129</td>\n",
       "      <td>2.819643</td>\n",
       "      <td>1.571712</td>\n",
       "      <td>0.935972</td>\n",
       "      <td>0.406948</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>-0.630365</td>\n",
       "      <td>1.991043</td>\n",
       "      <td>0.462783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>0.880180</td>\n",
       "      <td>0.668551</td>\n",
       "      <td>0.115084</td>\n",
       "      <td>-0.373637</td>\n",
       "      <td>0.848817</td>\n",
       "      <td>-0.859218</td>\n",
       "      <td>-0.823580</td>\n",
       "      <td>0.051974</td>\n",
       "      <td>-1.144327</td>\n",
       "      <td>1.314224</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075571</td>\n",
       "      <td>3.199856</td>\n",
       "      <td>0.321025</td>\n",
       "      <td>0.897483</td>\n",
       "      <td>0.356881</td>\n",
       "      <td>1.262655</td>\n",
       "      <td>0.939693</td>\n",
       "      <td>-0.032762</td>\n",
       "      <td>0.801281</td>\n",
       "      <td>0.081143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>-0.990084</td>\n",
       "      <td>-1.094018</td>\n",
       "      <td>3.645894</td>\n",
       "      <td>-0.474362</td>\n",
       "      <td>-1.129270</td>\n",
       "      <td>0.188591</td>\n",
       "      <td>0.092048</td>\n",
       "      <td>0.252823</td>\n",
       "      <td>-0.377933</td>\n",
       "      <td>0.510161</td>\n",
       "      <td>...</td>\n",
       "      <td>4.246089</td>\n",
       "      <td>1.513936</td>\n",
       "      <td>1.893477</td>\n",
       "      <td>1.733179</td>\n",
       "      <td>0.707100</td>\n",
       "      <td>1.219381</td>\n",
       "      <td>-0.573497</td>\n",
       "      <td>-0.156859</td>\n",
       "      <td>-0.796013</td>\n",
       "      <td>-0.849146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>-0.133272</td>\n",
       "      <td>-0.074305</td>\n",
       "      <td>-0.554388</td>\n",
       "      <td>-0.582548</td>\n",
       "      <td>0.307454</td>\n",
       "      <td>-0.958630</td>\n",
       "      <td>-1.523819</td>\n",
       "      <td>-1.589983</td>\n",
       "      <td>-3.622496</td>\n",
       "      <td>-5.815839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487263</td>\n",
       "      <td>4.062586</td>\n",
       "      <td>5.037271</td>\n",
       "      <td>4.045322</td>\n",
       "      <td>3.617340</td>\n",
       "      <td>0.939408</td>\n",
       "      <td>1.039827</td>\n",
       "      <td>5.210938</td>\n",
       "      <td>2.457164</td>\n",
       "      <td>1.430688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0    -1.094000 -1.280592  2.806926 -0.097576 -0.791472  2.440896  0.003710   \n",
       "1    -1.285544 -0.940198 -0.721321 -0.172044 -2.127893  2.549762  1.365750   \n",
       "2     0.503962  0.497136 -0.319168  0.330719 -0.398783 -0.749429 -2.380589   \n",
       "3    -1.119978  0.696697  0.612882 -0.983295  1.333148  1.557607 -0.999593   \n",
       "4     1.256214  1.066239  0.984965 -0.312513 -2.111077  0.009980  0.509741   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1054  0.089066  0.045324 -0.527161  0.274475  0.113220 -1.011250 -1.071873   \n",
       "1055  0.558342  0.274368 -0.356357 -0.410656  0.710800 -0.240603 -0.370162   \n",
       "1056  0.880180  0.668551  0.115084 -0.373637  0.848817 -0.859218 -0.823580   \n",
       "1057 -0.990084 -1.094018  3.645894 -0.474362 -1.129270  0.188591  0.092048   \n",
       "1058 -0.133272 -0.074305 -0.554388 -0.582548  0.307454 -0.958630 -1.523819   \n",
       "\n",
       "            F8        F9       F10  ...       F59       F60       F61  \\\n",
       "0    -0.864715  0.738257 -0.185613  ...  0.465685  1.651588  0.169668   \n",
       "1     0.489953  1.692462  0.387044  ...  0.534732 -0.935377 -1.176909   \n",
       "2     0.951098 -0.452177 -0.761333  ...  0.274432  0.150854  0.161782   \n",
       "3    -1.067051  0.811559  0.437626  ...  0.696481  0.091214 -0.051819   \n",
       "4     0.837961  0.420966  0.366289  ...  1.816629  0.593634  0.746647   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1054 -1.533993 -3.432258 -5.225601  ...  0.269233  3.032646  3.000290   \n",
       "1055  0.870655 -1.488764  0.566561  ...  1.723216  3.048129  2.819643   \n",
       "1056  0.051974 -1.144327  1.314224  ...  1.075571  3.199856  0.321025   \n",
       "1057  0.252823 -0.377933  0.510161  ...  4.246089  1.513936  1.893477   \n",
       "1058 -1.589983 -3.622496 -5.815839  ...  0.487263  4.062586  5.037271   \n",
       "\n",
       "           F62       F63       F64       F65       F66       F67       F68  \n",
       "0     0.348005 -0.385988 -0.137105 -0.421766 -0.296043 -0.731677 -0.442480  \n",
       "1    -1.408592 -0.986426 -1.293346 -1.239692 -0.729675 -1.153275 -1.254825  \n",
       "2     0.101072 -0.071694 -0.835381 -0.397305 -0.456676 -0.492329 -0.761836  \n",
       "3     0.219476  0.001850 -0.088704 -0.068108 -0.070306  0.277593 -0.071959  \n",
       "4     0.035940 -0.292118  0.075086 -0.238434 -0.347040 -0.693764  0.053940  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1054  2.279520  3.409849 -0.028728  1.661721  3.501781  2.685491  1.111113  \n",
       "1055  1.571712  0.935972  0.406948  0.725402 -0.630365  1.991043  0.462783  \n",
       "1056  0.897483  0.356881  1.262655  0.939693 -0.032762  0.801281  0.081143  \n",
       "1057  1.733179  0.707100  1.219381 -0.573497 -0.156859 -0.796013 -0.849146  \n",
       "1058  4.045322  3.617340  0.939408  1.039827  5.210938  2.457164  1.430688  \n",
       "\n",
       "[1059 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"music_scaled.csv\")\n",
    "X = data.iloc[:,:68]\n",
    "y = data[\"Latitude\"]\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68484080",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 1 (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2502e44",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) Perform linear regression of **y** on **X** using `sklearn.linear_model.LinearRegression` when the regressors consist of:\n",
    "- F1 only; \n",
    "- F1 and F2 only; \n",
    "- F1, F2, and F3 only; \n",
    "- F1, F2, F3, ........, and F68. \n",
    "\n",
    "b) In each of the above 4 cases, print the estimated coefficient for **F1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9a6879",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff F1 for LinearRegression model trained on X[:,0: 1] is 0.659734\n",
      "Coeff F1 for LinearRegression model trained on X[:,0: 2] is 1.669923\n",
      "Coeff F1 for LinearRegression model trained on X[:,0: 3] is 2.222158\n",
      "Coeff F1 for LinearRegression model trained on X[:,0: 4] is 2.324427\n",
      "Coeff F1 for LinearRegression model trained on X[:,0: 5] is 2.268298\n",
      "Coeff F1 for LinearRegression model trained on X[:,0: 6] is 2.845235\n",
      "Coeff F1 for LinearRegression model trained on X[:,0: 7] is 3.332087\n",
      "Coeff F1 for LinearRegression model trained on X[:,0: 8] is 3.356679\n",
      "Coeff F1 for LinearRegression model trained on X[:,0: 9] is 3.269857\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:10] is 3.303232\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:11] is 3.292077\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:12] is 3.320890\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:13] is 3.347535\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:14] is 3.326816\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:15] is 3.285898\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:16] is 2.973623\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:17] is 2.933209\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:18] is 5.019515\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:19] is 6.364016\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:20] is 4.998355\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:21] is 6.364778\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:22] is 4.133695\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:23] is 4.730007\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:24] is 4.981489\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:25] is 4.930128\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:26] is 5.093094\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:27] is 5.198480\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:28] is 5.163329\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:29] is 5.157667\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:30] is 5.312941\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:31] is 5.275585\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:32] is 5.282178\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:33] is 5.303313\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:34] is 4.938900\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:35] is 4.758449\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:36] is 3.920741\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:37] is 3.979084\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:38] is 3.655118\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:39] is 2.546008\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:40] is 2.426859\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:41] is 2.217109\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:42] is 2.310249\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:43] is 2.528894\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:44] is 2.577281\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:45] is 2.579688\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:46] is 2.777911\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:47] is 2.778351\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:48] is 2.750939\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:49] is 2.624263\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:50] is 2.613820\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:51] is 2.802340\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:52] is 2.730715\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:53] is 5.263762\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:54] is 6.424380\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:55] is 8.821812\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:56] is 9.162812\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:57] is 8.983055\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:58] is 8.984070\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:59] is 8.619820\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:60] is 8.961607\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:61] is 8.991983\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:62] is 8.923926\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:63] is 8.864724\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:64] is 8.697397\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:65] is 8.636580\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:66] is 8.896444\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:67] is 8.453820\n",
      "Coeff F1 for LinearRegression model trained on X[:,0:68] is 8.303671\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "for i in range(X.shape[1]):\n",
    "    coeffs_i = model.fit(X.iloc[:,:i+1],y)\n",
    "    print(f'Coeff F1 for LinearRegression model trained on X[:,0:{i+1:2}] is {coeffs_i.coef_[0]:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241910c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 2 (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9524d597",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) Perform a manual implementation to compute a full set of principal components of **X** using the following steps:\n",
    "- Compute the sample covariance matrix \n",
    "- Perform the eigen decomposition of the covariance matrix\n",
    "- Project the data onto the principal components (eigenvectors of the covariance matrix)\n",
    "\n",
    "\n",
    "b) Perform linear regression of **y** on the PCs using `sklearn.linear_model.LinearRegression` when the regressors consist of \n",
    "- PC1 only; \n",
    "- PC1 and PC2 only; \n",
    "- PC1, PC2, and PC3 only;\n",
    "- and PC1, PC2, PC3,  ........, and PC68. \n",
    "\n",
    "c) In each of the above 4 cases, print the estimated coefficient for **PC1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2de556",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = X.to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f10c99bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_mean =  X.mean(axis=1)[np.newaxis]\n",
    "X_norm = (X - X_mean.T)\n",
    "C = (X_norm @ X_norm.T) / (X.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca232d02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.53163805e-02 -5.34917047e-02  1.24463335e-01 ...  1.24187040e-01\n",
      "  -5.39367002e-01  4.05276290e-01]\n",
      " [-6.56485245e-02 -6.39472605e-02  1.95394851e-01 ...  8.90617762e-03\n",
      "   4.79952222e-01 -4.51821923e-01]\n",
      " [ 2.64016518e-02 -1.74354510e-01  1.46017715e-01 ... -1.03322170e-01\n",
      "  -5.31592446e-02 -2.03133315e-02]\n",
      " ...\n",
      " [-2.19513585e-01  4.70861118e-02  1.97728427e-02 ... -2.31882852e-01\n",
      "   3.51629833e-04 -1.71679372e-02]\n",
      " [-2.07908901e-01  5.45498221e-02  2.31983793e-02 ...  4.08714128e-01\n",
      "   1.34858715e-03  1.11392139e-02]\n",
      " [-1.84100793e-01  3.78032967e-02  3.08133404e-02 ... -2.58634779e-01\n",
      "   2.10911740e-03  1.13587698e-02]]\n",
      "[2.14881064e+02 1.27394978e+02 8.28128332e+01 7.52252605e+01\n",
      " 6.01153840e+01 3.56450275e+01 3.29628534e+01 2.95488651e+01\n",
      " 2.70883283e+01 2.33705421e+01 2.20670446e+01 2.05901873e+01\n",
      " 1.98397696e+01 1.75940962e+01 1.58917496e+01 1.53888493e+01\n",
      " 1.49037698e+01 1.46028604e+01 1.33415399e+01 1.28066744e+01\n",
      " 1.25648283e+01 1.10105340e+01 1.00304329e+01 9.75370925e+00\n",
      " 9.04484796e+00 8.48678659e+00 7.82412888e+00 7.62835773e+00\n",
      " 7.39242856e+00 7.12918059e+00 6.96642477e+00 6.62051506e+00\n",
      " 6.37047002e+00 6.23531289e+00 5.66438793e+00 5.30256457e+00\n",
      " 4.90429335e+00 4.50817017e+00 4.45081042e+00 4.27317832e+00\n",
      " 3.80632046e+00 3.46345504e+00 3.26709653e+00 3.17792786e+00\n",
      " 3.03475943e+00 2.91508764e+00 2.78791724e+00 2.73749539e+00\n",
      " 2.55627052e+00 2.36102325e+00 2.22497900e+00 2.19391580e+00\n",
      " 1.96675949e+00 1.78034028e+00 1.67542710e+00 1.60152871e+00\n",
      " 1.38972242e+00 1.30957048e+00 1.23733821e+00 1.17853179e+00\n",
      " 1.09863142e+00 1.02484100e+00 1.00244234e+00 8.99845010e-01\n",
      " 8.04932403e-01 6.90808823e-01 2.92059226e-01 9.39042503e-02]\n"
     ]
    }
   ],
   "source": [
    "L,E = np.linalg.eigh(C)\n",
    "\n",
    "L = L[::-1]\n",
    "E = E[:,::-1]\n",
    "\n",
    "print(E)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3db5bff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "A = E.T @ X # Project data onto principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3df69fa0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08259023])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(A[:1,:].T,y)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccaa64b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff F1 for LinearRegression model trained on X[:,: 1] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,: 2] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,: 3] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,: 4] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,: 5] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,: 6] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,: 7] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,: 8] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,: 9] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:10] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:11] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:12] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:13] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:14] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:15] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:16] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:17] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:18] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:19] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:20] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:21] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:22] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:23] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:24] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:25] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:26] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:27] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:28] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:29] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:30] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:31] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:32] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:33] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:34] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:35] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:36] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:37] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:38] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:39] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:40] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:41] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:42] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:43] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:44] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:45] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:46] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:47] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:48] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:49] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:50] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:51] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:52] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:53] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:54] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:55] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:56] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:57] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:58] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:59] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:60] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:61] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:62] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:63] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:64] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:65] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:66] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:67] is 0.082590\n",
      "Coeff F1 for LinearRegression model trained on X[:,:68] is 0.082590\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "A = A.T\n",
    "for i in range(X.shape[0]):\n",
    "    coeffs_i = model.fit(A[:,:i+1],y)\n",
    "    print(f'Coeff F1 for LinearRegression model trained on X[:,:{i+1:2}] is {coeffs_i.coef_[0]:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8977cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 3 (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac22727",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) What do you observe in terms of estimated coefficients of **F1** when the number of regressors are increased compared to the estimated coefficients of **PC1** when the number of regressors are increased?\n",
    "\n",
    "b) Explain the reason behind this observation.\n",
    "\n",
    "Answer: For the estimated coefficients of **F1**, we observe that as the number of regressors increase, it change and vary. This shows that The slope in the first dimension changes as the number of regressors change.\n",
    "\n",
    "However, we observed almost no change in the estimated coefficients of **PC1** when we project the data points into the PC space. This is what I was expecting at the beginning as well. The reason is that when we project data into the PC space, the basis vectors are linearly independent, henceforth, the coefficients should be the same, regardless of the number of PCi axis that we include. \n",
    "\n",
    "So PCi is orthogonal to PCj for $0 <= i,j <= 68$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19650f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 4 (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9548cda",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) Print the correlation matrix of all the PC's.\n",
    "\n",
    "b) Which matrix does it closely resemble to? \n",
    "\n",
    "c) Which feature of the principal components is depicted through this matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "810b9752",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -4.99600361e-16 -1.94289029e-16 ...  4.33680869e-18\n",
      "  -1.64798730e-17 -8.50014503e-17]\n",
      " [-4.99600361e-16  1.00000000e+00  9.54097912e-17 ... -8.67361738e-19\n",
      "  -2.77555756e-17 -9.54097912e-17]\n",
      " [-1.94289029e-16  9.54097912e-17  1.00000000e+00 ... -2.65412692e-16\n",
      "   9.70903045e-17  1.77863366e-16]\n",
      " ...\n",
      " [ 4.33680869e-18 -8.67361738e-19 -2.65412692e-16 ...  1.00000000e+00\n",
      "  -3.00134266e-16  1.39780765e-16]\n",
      " [-1.64798730e-17 -2.77555756e-17  9.70903045e-17 ... -3.00134266e-16\n",
      "   1.00000000e+00 -9.15337684e-17]\n",
      " [-8.50014503e-17 -9.54097912e-17  1.77863366e-16 ...  1.39780765e-16\n",
      "  -9.15337684e-17  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(E @ E.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "087ee887",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1568553d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(E @ E.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d7310",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It closely resembles the Identity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e308779",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(E@E.T, np.eye(68))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dcc2e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows that princple components are orthogonal to each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ddd890daad9ccb684bff25183d61c9f8150c8b957a775d488269053124e5aa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}